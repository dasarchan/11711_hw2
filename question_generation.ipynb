{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "def generate_question(chunk, model_name=\"llama3.2\"):\n",
    "    \"\"\"\n",
    "    Generate a single question-answer pair from a given text chunk using an Ollama model.\n",
    "    \n",
    "    Args:\n",
    "        chunk (str): The text chunk to generate a QA pair from\n",
    "        model_name (str): The name of the Ollama model to use (default: \"llama3.2\")\n",
    "        \n",
    "    Returns:\n",
    "        str: Generated question-answer pair in tuple format\n",
    "    \"\"\"\n",
    "    # Ollama API endpoint (default is localhost on port 11434)\n",
    "    api_url = \"http://localhost:11434/api/generate\"\n",
    "    \n",
    "    # Create the prompt for question and answer generation\n",
    "    prompt = f\"\"\"\n",
    "    You are a helpful assistant that generates a question-answer pair from text.\n",
    "    \n",
    "    Generate exactly 1 relevant question-answer pair from the following text:\n",
    "    \n",
    "    {chunk}\n",
    "    \n",
    "    Format requirements:\n",
    "    1. Output the pair as a Python tuple format: (\"Question text\", \"Answer text\")\n",
    "    2. Make sure the answer is directly supported by the provided text\n",
    "    3. Do not include ANY explanations, comments, or additional text\n",
    "    4. Do not include any numbering or prefixes\n",
    "    5. Ensure the tuple formatting is correct with proper quotes and parentheses\n",
    "    \"\"\"\n",
    "    \n",
    "    # Prepare the request payload\n",
    "    payload = {\n",
    "        \"model\": model_name,\n",
    "        \"prompt\": prompt,\n",
    "        \"stream\": False\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        # Make the API request to Ollama\n",
    "        response = requests.post(api_url, json=payload)\n",
    "        response.raise_for_status()  # Raise exception for HTTP errors\n",
    "        \n",
    "        # Parse the response\n",
    "        result = response.json()\n",
    "        return result[\"response\"].strip()\n",
    "    \n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error communicating with Ollama: {e}\")\n",
    "        return None\n",
    "    except (KeyError, json.JSONDecodeError) as e:\n",
    "        print(f\"Error processing Ollama response: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(\"Where were the games played for the 2020 World Series?\", \"Arlington, Texas, at Globe Life Field\")\n"
     ]
    }
   ],
   "source": [
    "chunk = \"The Los Angeles Dodgers won the World Series in 2020. The games were played in Arlington, Texas, at Globe Life Field due to the COVID-19 pandemic.\"\n",
    "\n",
    "questions = generate_question(chunk, model_name=\"llama3.2\")\n",
    "print(questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# questions.strip().split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11747\n"
     ]
    }
   ],
   "source": [
    "## read csv file\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"all_combined.csv\", lineterminator='\\n')\n",
    "print(len(df[\"text\"]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current row index:  0\n",
      "current row index:  100\n",
      "current row index:  200\n",
      "current row index:  300\n",
      "current row index:  400\n",
      "current row index:  500\n",
      "current row index:  600\n",
      "current row index:  700\n",
      "current row index:  800\n",
      "current row index:  900\n",
      "current row index:  1000\n",
      "current row index:  1100\n",
      "current row index:  1200\n",
      "current row index:  1300\n",
      "current row index:  1400\n",
      "current row index:  1500\n",
      "current row index:  1600\n",
      "current row index:  1700\n",
      "current row index:  1800\n",
      "current row index:  1900\n",
      "current row index:  2000\n",
      "current row index:  2100\n",
      "current row index:  2200\n",
      "current row index:  2300\n",
      "current row index:  2400\n",
      "current row index:  2500\n",
      "current row index:  2600\n",
      "current row index:  2700\n",
      "current row index:  2800\n",
      "current row index:  2900\n",
      "current row index:  3000\n",
      "current row index:  3100\n",
      "current row index:  3200\n",
      "current row index:  3300\n",
      "current row index:  3400\n",
      "current row index:  3500\n",
      "current row index:  3600\n",
      "current row index:  3700\n",
      "current row index:  3800\n",
      "current row index:  3900\n",
      "current row index:  4000\n",
      "current row index:  4100\n",
      "current row index:  4200\n",
      "current row index:  4300\n",
      "current row index:  4400\n",
      "current row index:  4500\n",
      "current row index:  4600\n",
      "current row index:  4700\n",
      "current row index:  4800\n",
      "current row index:  4900\n",
      "current row index:  5000\n",
      "current row index:  5100\n",
      "current row index:  5200\n",
      "current row index:  5300\n",
      "current row index:  5400\n",
      "current row index:  5500\n",
      "current row index:  5600\n",
      "current row index:  5700\n",
      "current row index:  5800\n",
      "current row index:  5900\n",
      "current row index:  6000\n",
      "current row index:  6100\n",
      "current row index:  6200\n",
      "current row index:  6300\n",
      "current row index:  6400\n",
      "current row index:  6500\n",
      "current row index:  6600\n",
      "current row index:  6700\n",
      "current row index:  6800\n",
      "current row index:  6900\n",
      "current row index:  7000\n",
      "current row index:  7100\n",
      "current row index:  7200\n",
      "current row index:  7300\n",
      "current row index:  7400\n",
      "current row index:  7500\n",
      "current row index:  7600\n",
      "current row index:  7700\n",
      "current row index:  7800\n",
      "current row index:  7900\n",
      "current row index:  8000\n",
      "current row index:  8100\n",
      "current row index:  8200\n",
      "current row index:  8300\n",
      "current row index:  8400\n",
      "current row index:  8500\n",
      "current row index:  8600\n",
      "current row index:  8700\n",
      "current row index:  8800\n",
      "current row index:  8900\n",
      "current row index:  9000\n",
      "current row index:  9100\n",
      "current row index:  9200\n",
      "current row index:  9300\n",
      "current row index:  9400\n",
      "current row index:  9500\n",
      "current row index:  9600\n",
      "current row index:  9700\n",
      "current row index:  9800\n",
      "current row index:  9900\n",
      "current row index:  10000\n",
      "current row index:  10100\n",
      "current row index:  10200\n",
      "current row index:  10300\n",
      "current row index:  10400\n",
      "current row index:  10500\n",
      "current row index:  10600\n",
      "current row index:  10700\n",
      "current row index:  10800\n",
      "current row index:  10900\n",
      "current row index:  11000\n",
      "current row index:  11100\n",
      "current row index:  11200\n",
      "current row index:  11300\n",
      "current row index:  11400\n",
      "current row index:  11500\n",
      "current row index:  11600\n",
      "current row index:  11700\n"
     ]
    }
   ],
   "source": [
    "model_name = \"llama3.2\"\n",
    "# Create a list to store all questions\n",
    "all_questions = []\n",
    "# Create a file to log generation results\n",
    "log_file = open(f\"{model_name}_question_generation_log.txt\", \"w\")\n",
    "\n",
    "for i in range(len(df)):\n",
    "    if i % 100 == 0:\n",
    "        print(\"current row index: \", i)\n",
    "    attempts = 0\n",
    "    max_attempts = 5\n",
    "    question = None\n",
    "    \n",
    "    while attempts < max_attempts:\n",
    "        try:\n",
    "            question = generate_question(df[\"text\"][i], model_name=model_name)\n",
    "            # print(\"The text is: \", df[\"text\"][i])\n",
    "            if question:  # If we got a valid response\n",
    "                # print(\"-------- ---------\")\n",
    "                # print(question)\n",
    "                # print(\"-------- ---------\")\n",
    "                break\n",
    "            raise Exception(\"Empty response received\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            attempts += 1\n",
    "            print(f\"Attempt {attempts} failed: {str(e)}\")\n",
    "            if attempts == max_attempts:\n",
    "                print(f\"Failed to generate question after {max_attempts} attempts\")\n",
    "    \n",
    "    # Add the question to our list (empty string if generation failed)\n",
    "    if question:\n",
    "        all_questions.append(question)\n",
    "        log_file.write(f\"{i}\\t{question}\\n\")\n",
    "    else:\n",
    "        all_questions.append(\"\")\n",
    "        log_file.write(f\"{i}\\t\\n\")\n",
    "\n",
    "# Close the log file\n",
    "log_file.close()\n",
    "\n",
    "# After collecting all questions, add them as a new column\n",
    "column_name = f\"{model_name}_question\"\n",
    "df[column_name] = all_questions\n",
    "\n",
    "# Save the final dataframe once at the end\n",
    "df.to_csv(\"all_combined.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              source  \\\n",
      "0  https://www.heinzhistorycenter.org/event/irish...   \n",
      "1  https://www.heinzhistorycenter.org/event/one-o...   \n",
      "2  https://www.heinzhistorycenter.org/event/histo...   \n",
      "3  https://www.heinzhistorycenter.org/event/speak...   \n",
      "4  https://www.heinzhistorycenter.org/event/gut-y...   \n",
      "5  https://www.heinzhistorycenter.org/event/natio...   \n",
      "6  https://www.heinzhistorycenter.org/event/natio...   \n",
      "7  https://www.heinzhistorycenter.org/event/ameri...   \n",
      "8  https://www.heinzhistorycenter.org/event/vietn...   \n",
      "9  https://www.heinzhistorycenter.org/event/vinta...   \n",
      "\n",
      "                                                text  \\\n",
      "0  Skip Main NavigationSkip to site alert\\nHeinz ...   \n",
      "1  Skip Main NavigationSkip to site alert\\nHeinz ...   \n",
      "2  Skip Main NavigationSkip to site alert\\nHeinz ...   \n",
      "3  Skip Main NavigationSkip to site alert\\nHeinz ...   \n",
      "4  Skip Main NavigationSkip to site alert\\nHeinz ...   \n",
      "5  Skip Main NavigationSkip to site alert\\nHeinz ...   \n",
      "6  Skip Main NavigationSkip to site alert\\nHeinz ...   \n",
      "7  Skip Main NavigationSkip to site alert\\nHeinz ...   \n",
      "8  Skip Main NavigationSkip to site alert\\nHeinz ...   \n",
      "9  Skip Main NavigationSkip to site alert\\nHeinz ...   \n",
      "\n",
      "                                   llama3.2_question  \n",
      "0  (\"What is the date of the Irish Genealogy Work...  \n",
      "1  (\"What is a personal consultation with the Uls...  \n",
      "2  (\"When does History Uncorked: Mirror Ball take...  \n",
      "3  (\"What is the title of Jason A. Cherry's new b...  \n",
      "4  (\"What does Gut Yontif mean?\", \"Have a good ho...  \n",
      "5  (\"What is National History Day?\", \"a competiti...  \n",
      "6  (\"What is National History Day?\", \"National Hi...  \n",
      "7  (\"What time does the tea party take place?\", \"...  \n",
      "8  (\"When is the Vietnam Veterans Day event at He...  \n",
      "9  (\"What is included with regular museum admissi...  \n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"all_combined.csv\", lineterminator='\\n')\n",
    "print(df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anlp-hw2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
